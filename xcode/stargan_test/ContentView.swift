import SwiftUI
import CoreML
import AVFoundation
import VideoToolbox

// ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆ (å¤‰æ›´ãªã—)
let domains = [
    "bibimpbap", "chahan", "chikenrice", "curry", "ebichill",
    "gratin", "gyudon", "hiyachu", "kaisendon", "katsudon",
    "meatspa", "omelet", "omurice", "oyakodon", "pilaf",
    "pizza", "ramen", "rice", "soba", "steak",
    "tendon", "unadon", "yakisoba"
]
// UIImageæ‹¡å¼µæ©Ÿèƒ½
extension UIImage {
    // ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç„¡è¦–ã—ã¦ãƒªã‚µã‚¤ã‚º (ä»Šå›ã¯ä½¿ç”¨ã—ãªã„å¯èƒ½æ€§ã‚ã‚Š)
    func resize(to size: CGSize) -> UIImage? {
        UIGraphicsBeginImageContextWithOptions(size, false, 0.0)
        defer { UIGraphicsEndImageContext() }
        self.draw(in: CGRect(origin: .zero, size: size))
        return UIGraphicsGetImageFromCurrentImageContext()
    }
    
    // --- è¿½åŠ : ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ã¦ãƒªã‚µã‚¤ã‚ºï¼†ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ— ---
    func resizeAspectFill(to targetSize: CGSize) -> UIImage? {
        guard let cgImage = self.cgImage else { return nil }
        
        let imageSize = self.size
        let targetWidth = targetSize.width
        let targetHeight = targetSize.height
        
        // ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
        let widthRatio = targetWidth / imageSize.width
        let heightRatio = targetHeight / imageSize.height
        
        // Fill ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’é¸æŠ (å¤§ãã„æ–¹ã®æ¯”ç‡ã‚’ä½¿ã†)
        let scaleFactor = max(widthRatio, heightRatio)
        
        // ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        let scaledWidth = imageSize.width * scaleFactor
        let scaledHeight = imageSize.height * scaleFactor
        
        // æç”»ã™ã‚‹é ˜åŸŸï¼ˆä¸­å¤®æƒãˆï¼‰ã‚’è¨ˆç®—
        let drawingRect = CGRect(
            x: (targetWidth - scaledWidth) / 2.0,
            y: (targetHeight - scaledHeight) / 2.0,
            width: scaledWidth,
            height: scaledHeight
        )
        
        // æç”»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        UIGraphicsBeginImageContextWithOptions(targetSize, false, self.scale) // scaleã‚’è€ƒæ…®
        defer { UIGraphicsEndImageContext() }
        
        // ç”»åƒã‚’æç”»
        self.draw(in: drawingRect)
        
        // æ–°ã—ã„UIImageã‚’å–å¾—
        let newImage = UIGraphicsGetImageFromCurrentImageContext()
        return newImage
    }
    
    func rotateLeft() -> UIImage? {
        guard let cgImage = self.cgImage else { return nil }
        return UIImage(cgImage: cgImage, scale: self.scale, orientation: .left)
    }
    
    func rotateRight() -> UIImage? {
        guard let cgImage = self.cgImage else { return nil }
        return UIImage(cgImage: cgImage, scale: self.scale, orientation: .right)
    }
    
    // UIImageã‹ã‚‰CVPixelBufferã¸ã®å¤‰æ›é–¢æ•° (ãƒ­ã‚°è¿½åŠ )
    func toCVPixelBuffer(size: CGSize) -> CVPixelBuffer? {
        let attributes = [
            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue,
            kCVPixelBufferIOSurfacePropertiesKey: [:]
        ] as CFDictionary
        var pixelBuffer: CVPixelBuffer?
        let status = CVPixelBufferCreate(kCFAllocatorDefault,
                                         Int(size.width),
                                         Int(size.height),
                                         kCVPixelFormatType_32ARGB, // Use ARGB for context compatibility
                                         attributes,
                                         &pixelBuffer)
        
        guard status == kCVReturnSuccess, let unwrappedPixelBuffer = pixelBuffer else {
            print("Error [toCVPixelBuffer]: Failed to create pixel buffer. Status: \(status)") // è©³ç´°ãƒ­ã‚°
            return nil
        }
        
        CVPixelBufferLockBaseAddress(unwrappedPixelBuffer, CVPixelBufferLockFlags(rawValue: 0))
        defer { CVPixelBufferUnlockBaseAddress(unwrappedPixelBuffer, CVPixelBufferLockFlags(rawValue: 0)) }
        
        guard let pixelData = CVPixelBufferGetBaseAddress(unwrappedPixelBuffer) else {
            print("Error [toCVPixelBuffer]: Failed to get base address of pixel buffer.")
            return nil
        }
        print("[toCVPixelBuffer]: Pixel buffer base address obtained.") // æˆåŠŸãƒ­ã‚°
        
        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
        // Use CGImageAlphaInfo.noneSkipFirst for ARGB format
        let bitmapInfo = CGImageAlphaInfo.noneSkipFirst.rawValue | CGBitmapInfo.byteOrder32Little.rawValue // Use Little Endian for iOS typical context
        
        guard let context = CGContext(data: pixelData,
                                      width: Int(size.width),
                                      height: Int(size.height),
                                      bitsPerComponent: 8,
                                      bytesPerRow: CVPixelBufferGetBytesPerRow(unwrappedPixelBuffer),
                                      space: rgbColorSpace,
                                      bitmapInfo: bitmapInfo)
        else {
            print("Error [toCVPixelBuffer]: Failed to create CGContext.")
            return nil
        }
        print("[toCVPixelBuffer]: CGContext created successfully.") // æˆåŠŸãƒ­ã‚°
        
        // Draw image into context, adjusting for coordinate differences
        context.translateBy(x: 0, y: size.height)
        context.scaleBy(x: 1.0, y: -1.0)
        
        UIGraphicsPushContext(context)
        self.draw(in: CGRect(x: 0, y: 0, width: size.width, height: size.height))
        UIGraphicsPopContext()
        print("[toCVPixelBuffer]: Image drawn into context.") // æˆåŠŸãƒ­ã‚°
        
        return unwrappedPixelBuffer
    }
}

// CameraManager ã‚¯ãƒ©ã‚¹ (å¤‰æ›´ãªã—)
class CameraManager: NSObject, ObservableObject {
    @Published var currentFrame: UIImage?
    @Published var isRunning = false
    
    private let captureSession = AVCaptureSession()
    private let videoOutput = AVCaptureVideoDataOutput()
    private let sessionQueue = DispatchQueue(label: "sessionQueue")
    
    override init() {
        super.init()
        setupCaptureSession()
    }
    
    private func setupCaptureSession() {
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
              let input = try? AVCaptureDeviceInput(device: camera) else {
            print("ã‚«ãƒ¡ãƒ©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
            return
        }
        
        captureSession.beginConfiguration()
        
        if captureSession.canAddInput(input) {
            captureSession.addInput(input)
        }
        
        videoOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue"))
        videoOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA)]
        if captureSession.canAddOutput(videoOutput) {
            captureSession.addOutput(videoOutput)
        }
        
        captureSession.sessionPreset = .hd1280x720
        captureSession.commitConfiguration()
    }
    
    func startCapture() {
        guard !isRunning else { return }
        sessionQueue.async { [weak self] in
            self?.captureSession.startRunning()
            DispatchQueue.main.async { self?.isRunning = true }
        }
    }
    
    func stopCapture() {
        guard isRunning else { return }
        sessionQueue.async { [weak self] in
            self?.captureSession.stopRunning()
            DispatchQueue.main.async { self?.isRunning = false }
        }
    }
}

extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                       didOutput sampleBuffer: CMSampleBuffer,
                       from connection: AVCaptureConnection) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        var cgImage: CGImage?
        VTCreateCGImageFromCVPixelBuffer(pixelBuffer, options: nil, imageOut: &cgImage)
        guard let capturedCGImage = cgImage else { return }
        let image = UIImage(cgImage: capturedCGImage)
        DispatchQueue.main.async { [weak self] in self?.currentFrame = image }
    }
}

// CameraPreviewView (å¤‰æ›´ãªã—)
struct CameraPreviewView: UIViewRepresentable {
    @ObservedObject var cameraManager: CameraManager
    
    func makeUIView(context: Context) -> UIView {
        let view = UIView(frame: UIScreen.main.bounds)
        view.backgroundColor = .black
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {}
}

// StyleThumbnailView (å¤‰æ›´ãªã—)
struct StyleThumbnailView: View {
    let styleName: String
    let isSelected: Bool
    
    var body: some View {
        VStack {
            ZStack {
                Rectangle()
                    .fill(Color.gray.opacity(0.3))
                    .aspectRatio(1, contentMode: .fit)
                    .cornerRadius(8)
                
                Text(styleName)
                    .font(.caption)
                    .foregroundColor(.white)
                    .padding(4)
            }
        }
        .padding(4)
        .overlay(
            RoundedRectangle(cornerRadius: 10)
                .stroke(isSelected ? Color.blue : Color.clear, lineWidth: 3)
        )
    }
}

struct ContentView: View {
    // @StateObject, @State å¤‰æ•° (å¤‰æ›´ãªã—)
    @StateObject private var cameraManager = CameraManager()
    @State private var selectedDomain: String = domains.first!
    @State private var inputImage: UIImage? = nil
    @State private var convertedImage: UIImage? = nil
    @State private var isProcessing = false
    @State private var processingDuration: TimeInterval = 0
    @State private var debugMessages: [String] = []
    @State private var showDebugInfo = true
    
    // ãƒ¢ãƒ‡ãƒ« (ã‚¯ãƒ©ã‚¹åã¯è¦ç¢ºèªãƒ»ä¿®æ­£)
    private let model: StarGANv2_256
    
    // å‚ç…§ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ (å¤‰æ›´ãªã—)
    @State private var referenceImageCache: [String: UIImage] = [:]
    
    init() {
        print("â„¹ï¸ ContentView initializing...")
        do {
            let configuration = MLModelConfiguration()
            model = try StarGANv2_256(configuration: configuration) // <<< ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹åã‚’ç¢ºèªãƒ»ä¿®æ­£
            print("âœ… Model loaded successfully.")
            print("Input Descriptions: \(model.model.modelDescription.inputDescriptionsByName)")
            print("Output Descriptions: \(model.model.modelDescription.outputDescriptionsByName)")
        } catch {
            print("âŒ Fatal Error: Failed to load model: \(error.localizedDescription)")
            fatalError("Failed to load model: \(error.localizedDescription)")
        }
        print("â„¹ï¸ ContentView initialized.")
    }
    
    // MARK: - Body
    var body: some View {
        GeometryReader { geometry in
            VStack(spacing: 0) {
                // ç”»åƒè¡¨ç¤ºã‚¨ãƒªã‚¢
                HStack(spacing: 0) {
                    // --- 1a. å…¥åŠ›ç”»åƒï¼ˆå·¦å´ï¼‰---
                    // è¡¨ç¤ºã™ã‚‹ç”»åƒãŒ inputImage (å‰å‡¦ç†æ¸ˆã¿) ã«å¤‰ã‚ã£ãŸ
                    ZStack {
                        Color.gray.opacity(0.1).edgesIgnoringSafeArea(.top)
                        if let image = inputImage { // inputImage ã‚’è¡¨ç¤º
                            Image(uiImage: image)
                                .resizable()
                                .scaledToFit()
                                .frame(maxWidth: .infinity, maxHeight: .infinity)
                        } else {
                            Rectangle().fill(Color.gray.opacity(0.3))
                        }
                        VStack { Spacer(); Text("å…¥åŠ› (ãƒ¢ãƒ‡ãƒ«ç”¨)").font(.caption).foregroundColor(.white).padding(.horizontal, 6).padding(.vertical, 2).background(Color.black.opacity(0.6)).cornerRadius(4).padding(5) } // ãƒ©ãƒ™ãƒ«å¤‰æ›´
                    }
                    .frame(width: geometry.size.width / 2)
                    .clipped()
                    
                    // --- 1b. å¤‰æ›å¾Œã®ç”»åƒï¼ˆå³å´ï¼‰--- (å¤‰æ›´ãªã—)
                    ZStack {
                        Color.gray.opacity(0.1).edgesIgnoringSafeArea(.top)
                        if let image = convertedImage {
                            Image(uiImage: image)
                                .resizable()
                                .scaledToFit()
                                .frame(maxWidth: .infinity, maxHeight: .infinity)
                        } else {
                            Rectangle().fill(Color.gray.opacity(0.3))
                        }
                        VStack { Spacer(); Text("å‡ºåŠ›").font(.caption).foregroundColor(.white).padding(.horizontal, 6).padding(.vertical, 2).background(Color.black.opacity(0.6)).cornerRadius(4).padding(5) }
                    }
                    .frame(width: geometry.size.width / 2)
                    .clipped()
                }
                .frame(height: geometry.size.height * 0.7)
                
                // --- 2. ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠéƒ¨åˆ† ---
                ScrollView(.horizontal, showsIndicators: false) {
                    LazyHGrid(rows: [GridItem(.fixed(80))], spacing: 10) { // é«˜ã•ã‚’å›ºå®š
                        ForEach(domains, id: \.self) { domain in
                            StyleThumbnailView(styleName: domain, isSelected: selectedDomain == domain)
                                .onTapGesture {
                                    if selectedDomain != domain {
                                        selectedDomain = domain
                                        addDebugMessage("ğŸ‘‰ Style changed to: \(domain)")
                                        // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¹ã‚¿ã‚¤ãƒ«å¤‰æ›´æ™‚ã«å³æ™‚å¤‰æ›
                                        // if let currentFrame = cameraManager.currentFrame, !isProcessing {
                                        //     convertImage(image: currentFrame)
                                        // }
                                    }
                                }
                        }
                    }
                    .padding(.horizontal) // å·¦å³ã«ä½™ç™½
                    .padding(.vertical, 5) // ä¸Šä¸‹ã«å°‘ã—ä½™ç™½
                }
                .frame(height: 90) // ScrollViewè‡ªä½“ã®é«˜ã•ã‚’å›ºå®š (GridItemã®é«˜ã• + padding)
                .background(Color.black.opacity(0.85)) // èƒŒæ™¯è‰²ã‚’å°‘ã—æ¿ƒã
                
                // --- 3. ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º ---
                VStack(alignment: .leading, spacing: 4) { // ãƒ‡ãƒãƒƒã‚°æƒ…å ±å…¨ä½“ã®VStack
                    // --- 3a. ãƒ˜ãƒƒãƒ€ãƒ¼ã¨é–‹é–‰ãƒœã‚¿ãƒ³ ---
                    HStack {
                        Text("ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
                            .font(.headline)
                            .foregroundColor(.white)
                        Spacer() // ãƒœã‚¿ãƒ³ã‚’å³å¯„ã›
                        Button {
                            withAnimation { // é–‹é–‰ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
                                showDebugInfo.toggle()
                            }
                        } label: {
                            Image(systemName: showDebugInfo ? "chevron.up.circle.fill" : "chevron.down.circle.fill")
                                .foregroundColor(.gray)
                                .font(.title3) // ã‚¢ã‚¤ã‚³ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´
                        }
                    }
                    .padding(.horizontal)
                    .padding(.top, 5) // ä¸Šéƒ¨ã«å°‘ã—ä½™ç™½
                    
                    // --- 3b. ãƒ‡ãƒãƒƒã‚°å†…å®¹ (è¡¨ç¤ºçŠ¶æ…‹ã«å¿œã˜ã¦è¡¨ç¤º) ---
                    if showDebugInfo {
                        ScrollView(.vertical) { // ç¸¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ã«ã™ã‚‹
                            VStack(alignment: .leading, spacing: 4) {
                                // å‡¦ç†æ™‚é–“
                                Text("å‡¦ç†æ™‚é–“: \(String(format: "%.3f", processingDuration))ç§’")
                                    .font(.caption)
                                    .foregroundColor(.gray) // å°‘ã—è‰²ã‚’è–„ã
                                
                                Divider().background(Color.gray) // åŒºåˆ‡ã‚Šç·š
                                
                                // ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (æ–°ã—ã„ã‚‚ã®ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«é€†é †è¡¨ç¤º)
                                ForEach(debugMessages.reversed().indices, id: \.self) { index in
                                    Text(debugMessages.reversed()[index])
                                        .font(.system(size: 10, design: .monospaced)) // ç­‰å¹…ãƒ•ã‚©ãƒ³ãƒˆ
                                        .foregroundColor(.white)
                                        .lineLimit(2) // 2è¡Œã¾ã§è¡¨ç¤º
                                        .frame(maxWidth: .infinity, alignment: .leading) // å·¦å¯„ã›
                                }
                            }
                            .padding(.horizontal) // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å†…ã®å·¦å³ä½™ç™½
                            .padding(.bottom, 5) // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å†…ã®ä¸‹éƒ¨ä½™ç™½
                        }
                        // ScrollViewã®æœ€å¤§é«˜ã•ã‚’è¨­å®šã—ã¦ã€ä¼¸ã³ã™ããªã„ã‚ˆã†ã«ã™ã‚‹
                        .frame(maxHeight: 100)
                    }
                }
                .background(Color.black.opacity(0.85)) // ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒªã‚¢å…¨ä½“ã®èƒŒæ™¯
                
                // --- Spacerã‚’è¿½åŠ ã—ã¦ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ä¸‹éƒ¨ã«æŠ¼ã—ã‚„ã‚‹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ---
                // Spacer()
                
            } // å…¨ä½“ã®VStack
            .background(Color.black) // èƒŒæ™¯è‰²
            .edgesIgnoringSafeArea(.bottom) // ä¸‹ã®SafeAreaã‚’ç„¡è¦–
            .onAppear {
                addDebugMessage("ContentView appeared. Starting camera...")
                cameraManager.startCapture()
            }
            .onDisappear {
                addDebugMessage("ContentView disappeared. Stopping camera...")
                cameraManager.stopCapture()
            }
            .onChange(of: cameraManager.currentFrame) { newFrame in
                // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã‚’ä¿è¨¼ (ã‚ˆã‚Šå®‰å…¨)
                DispatchQueue.main.async {
                    guard let frame = newFrame else { return }
                    if !isProcessing {
                        convertImage(image: frame)
                    }
                }
            }
        } // GeometryReader
    } // body
    
    // ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ  (ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ)
    private func addDebugMessage(_ message: String) {
        DispatchQueue.main.async {
            let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
            // çµµæ–‡å­—ã‚’è¿½åŠ ã—ã¦è¦–èªæ€§å‘ä¸Š
            let prefix: String
            if message.starts(with: "Error") || message.starts(with: "âŒ") { prefix = "âŒ " }
            else if message.starts(with: "Warning") || message.starts(with: "âš ï¸") { prefix = "âš ï¸ " }
            else if message.starts(with: "âœ…") { prefix = "âœ… " }
            else if message.starts(with: "ğŸ‘‰") { prefix = "ğŸ‘‰ " }
            else { prefix = "â„¹ï¸ " } // æƒ…å ±
            
            let fullMessage = "[\(timestamp)] \(prefix)\(message)"
            debugMessages.append(fullMessage)
            if debugMessages.count > 100 { // ãƒ­ã‚°ä»¶æ•°åˆ¶é™
                debugMessages.removeFirst(debugMessages.count - 100)
            }
            print(fullMessage) // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å¸¸ã«å‡ºåŠ›
        }
    }
    
    // å‚ç…§ç”»åƒå–å¾— (ãƒ­ã‚°è¿½åŠ )
    private func getReferenceImage(for domain: String) -> UIImage? {
        if let cachedImage = referenceImageCache[domain] {
            addDebugMessage("Reference image cache hit for: \(domain)")
            return cachedImage
        }
        addDebugMessage("Reference image cache miss for: \(domain). Loading from Assets...")
        guard let loadedImage = UIImage(named: domain) else {
            addDebugMessage("Error: Failed to load reference image from Assets for: \(domain)")
            return nil
        }
        addDebugMessage("Reference image loaded from Assets: \(domain)")
        DispatchQueue.main.async {
            referenceImageCache[domain] = loadedImage // ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        }
        return loadedImage
    }
    
    // --- è¿½åŠ : å…¨å‚ç…§ç”»åƒã‚’éåŒæœŸã§äº‹å‰ã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ ---
    private func loadReferenceImagesAsync() {
        DispatchQueue.global(qos: .background).async {
            addDebugMessage("å…¨å‚ç…§ç”»åƒã®äº‹å‰ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
            var loadedCount = 0
            for domain in domains {
                if referenceImageCache[domain] == nil { // ã¾ã ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ãƒ­ãƒ¼ãƒ‰
                    if let loadedImage = UIImage(named: domain) {
                        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ (ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§)
                        DispatchQueue.main.async {
                            self.referenceImageCache[domain] = loadedImage
                            loadedCount += 1
                        }
                    } else {
                        addDebugMessage("Warning: äº‹å‰ãƒ­ãƒ¼ãƒ‰å¤±æ•—: \(domain)")
                    }
                }
            }
            addDebugMessage("å…¨å‚ç…§ç”»åƒã®äº‹å‰ãƒ­ãƒ¼ãƒ‰å®Œäº† (\(loadedCount)ä»¶)")
        }
    }
    
    // MARK: - Image Conversion Logic
    private func convertImage(image: UIImage) { // image ã¯ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ç”Ÿãƒ•ãƒ¬ãƒ¼ãƒ 
        guard !isProcessing else { return }
        
        let startTime = Date()
        let currentSelectedDomain = selectedDomain
        addDebugMessage("Starting image conversion for style: \(currentSelectedDomain)")
        
        guard let domainIndex = domains.firstIndex(of: currentSelectedDomain) else {
            addDebugMessage("Error: Could not find domain index for: \(currentSelectedDomain)")
            return
        }
        let targetSize = CGSize(width: 256, height: 256)
        
        DispatchQueue.main.async { self.isProcessing = true; self.processingDuration = 0 }
        
        DispatchQueue.global(qos: .userInitiated).async {
            var finalConvertedImage: UIImage? = nil
            var finalProcessingTime: TimeInterval = 0
            var success = false
            
            do {
                // --- ä¿®æ­£: å…¥åŠ›ç”»åƒã®å‰å‡¦ç† ---
                addDebugMessage("[1/7] Rotating and preprocessing (resizeAspectFill) input image...")
                guard let rotatedImage = image.rotateRight(),
                      // â˜…â˜…â˜… resizeAspectFill ã‚’ä½¿ç”¨ â˜…â˜…â˜…
                      let preprocessedInputImage = rotatedImage.resizeAspectFill(to: targetSize) else {
                    throw ConversionError.preprocessingFailed("Input image rotation or resizeAspectFill failed.")
                }
                // â˜…â˜…â˜… ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‰å‡¦ç†æ¸ˆã¿ç”»åƒ inputImage ã‚’æ›´æ–° â˜…â˜…â˜…
                DispatchQueue.main.async { self.inputImage = preprocessedInputImage }
                addDebugMessage("âœ… [1/7] Input image preprocessed.")
                // --- ä¿®æ­£ã“ã“ã¾ã§ ---
                
                // --- ä¿®æ­£: CVPixelBufferã«ã¯å‰å‡¦ç†æ¸ˆã¿ç”»åƒã‚’ä½¿ã† ---
                addDebugMessage("[2/7] Converting preprocessed input image to CVPixelBuffer...")
                guard let sourcePixelBuffer = preprocessedInputImage.toCVPixelBuffer(size: targetSize) else { // â˜…â˜…â˜… preprocessedInputImage ã‚’ä½¿ç”¨ â˜…â˜…â˜…
                    throw ConversionError.bufferCreationFailed("Input image CVPixelBuffer creation failed.")
                }
                addDebugMessage("âœ… [2/7] Input image CVPixelBuffer created.")
                // --- ä¿®æ­£ã“ã“ã¾ã§ ---
                
                
                addDebugMessage("[3/7] Getting reference image for \(currentSelectedDomain)...")
                guard let referenceUIImage = self.getReferenceImage(for: currentSelectedDomain) else {
                    throw ConversionError.referenceImageLoadFailed("Reference UIImage load failed for \(currentSelectedDomain).")
                }
                addDebugMessage("âœ… [3/7] Reference UIImage loaded.")
                
                // --- ä¿®æ­£: å‚ç…§ç”»åƒã‚‚ resizeAspectFill ã‚’ä½¿ã†ï¼ˆä»»æ„ï¼‰---
                // ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãŸã„å ´åˆã¯ã“ã¡ã‚‰ã‚‚å¤‰æ›´ã€‚ãã†ã§ãªã‘ã‚Œã° resize ã®ã¾ã¾ã§ã‚‚OKã€‚
                addDebugMessage("[4/7] Preprocessing (resizeAspectFill) reference image...")
                guard let preprocessedRefImage = referenceUIImage.resizeAspectFill(to: targetSize) else { // â˜…â˜…â˜… resizeAspectFill ã‚’ä½¿ç”¨ â˜…â˜…â˜…
                    throw ConversionError.preprocessingFailed("Reference image resizeAspectFill failed.")
                }
                addDebugMessage("âœ… [4/7] Reference image preprocessed.")
                // --- ä¿®æ­£ã“ã“ã¾ã§ ---
                
                
                // --- ä¿®æ­£: CVPixelBufferã«ã¯å‰å‡¦ç†æ¸ˆã¿å‚ç…§ç”»åƒã‚’ä½¿ã† ---
                addDebugMessage("[5/7] Converting preprocessed reference image to CVPixelBuffer...")
                guard let referencePixelBuffer = preprocessedRefImage.toCVPixelBuffer(size: targetSize) else { // â˜…â˜…â˜… preprocessedRefImage ã‚’ä½¿ç”¨ â˜…â˜…â˜…
                    throw ConversionError.bufferCreationFailed("Reference image CVPixelBuffer creation failed.")
                }
                addDebugMessage("âœ… [5/7] Reference image CVPixelBuffer created.")
                // --- ä¿®æ­£ã“ã“ã¾ã§ ---
                
                addDebugMessage("[6/7] Preparing domain index MLMultiArray...")
                guard let domainIndexArray = try? MLMultiArray(shape: [1] as [NSNumber], dataType: .int32) else {
                    throw ConversionError.multiArrayCreationFailed("Domain index MLMultiArray creation failed.")
                }
                domainIndexArray[0] = NSNumber(value: Int32(domainIndex))
                addDebugMessage("âœ… [6/7] Domain index MLMultiArray prepared (index: \(domainIndex)).")
                
                
                addDebugMessage("[7/7] Performing model prediction...")
                // --- Inputã‚¯ãƒ©ã‚¹å (è¦ç¢ºèªãƒ»ä¿®æ­£) ---
                let input = StarGANv2_256Input(
                    source_image: sourcePixelBuffer,
                    reference_image: referencePixelBuffer,
                    reference_domain_index: domainIndexArray
                )
                
                let output = try self.model.prediction(input: input)
                addDebugMessage("âœ… [7/7] Model prediction successful.")
                
                // --- å‡ºåŠ›å (è¦ç¢ºèªãƒ»ä¿®æ­£) ---
                let outputMultiArray = output.generated_image_tensor
                addDebugMessage("Output tensor obtained, shape: \(outputMultiArray.shape). Converting to UIImage...")
                
                guard let outputUIImage = self.convertMultiArrayToUIImage(multiArray: outputMultiArray) else {
                    throw ConversionError.postprocessingFailed("Failed to convert output MLMultiArray to UIImage.")
                }
                addDebugMessage("âœ… Output UIImage conversion successful.")
                
                // æˆåŠŸæ™‚ã®çµæœã‚’ä¿æŒ
                finalConvertedImage = outputUIImage
                finalProcessingTime = Date().timeIntervalSince(startTime)
                success = true
                
            } catch let error as ConversionError { // è‡ªä½œã‚¨ãƒ©ãƒ¼
                self.addDebugMessage("Error during conversion: \(error.localizedDescription)")
            } catch { // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ (CoreMLã‚¨ãƒ©ãƒ¼ãªã©)
                let nsError = error as NSError
                self.addDebugMessage("âŒ Error during prediction: \(error.localizedDescription)")
                self.addDebugMessage("   Domain: \(nsError.domain), Code: \(nsError.code)")
                self.addDebugMessage("   UserInfo: \(nsError.userInfo)")
                print("âŒ Prediction Error Details: \(error)") // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°
            }
            
            // --- UIæ›´æ–° (ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰) ---
            DispatchQueue.main.async {
                if success {
                    self.convertedImage = finalConvertedImage
                    self.processingDuration = finalProcessingTime
                    self.addDebugMessage("âœ… Conversion finished successfully. Time: \(String(format: "%.3f", finalProcessingTime))s")
                } else {
                    // ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯å‡ºåŠ›ç”»åƒã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    // self.convertedImage = nil
                    self.addDebugMessage("âŒ Conversion failed.")
                }
                // å‡¦ç†å®Œäº†ãƒ•ãƒ©ã‚°ã‚’å¿…ãšä¸‹ã‚ã™
                self.isProcessing = false
            }
        }
    }
    
    
    // MLMultiArrayã‹ã‚‰UIImageã¸ã®å¤‰æ›
    private func convertMultiArrayToUIImage(multiArray: MLMultiArray) -> UIImage? {
        addDebugMessage("Converting MLMultiArray to UIImage (Input range: -1 to 1 assumed)")
        guard multiArray.dataType == .float32 else {
            addDebugMessage("Error [convertMultiArray]: MLMultiArray dataType is not Float32 (\(multiArray.dataType))")
            return nil
        }
        
        // --- ä¿®æ­£: ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’å‰Šé™¤ã—ã€ç›´æ¥ä»£å…¥ã¨ãƒã‚§ãƒƒã‚¯ ---
        guard multiArray.shape.count == 4, // æ¬¡å…ƒæ•°ãƒã‚§ãƒƒã‚¯
              multiArray.shape[0].intValue == 1, // ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
              multiArray.shape[1].intValue == 3  // ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        else {
            addDebugMessage("Error [convertMultiArray]: MLMultiArray shape dimension count or first dimensions are incorrect: \(multiArray.shape). Expected 4 dimensions starting with [1, 3, ...]")
            return nil
        }
        
        // shape.count == 4ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹2ã¨3ã¯å­˜åœ¨ã™ã‚‹
        let height = multiArray.shape[2].intValue // ç›´æ¥ä»£å…¥
        let width = multiArray.shape[3].intValue  // ç›´æ¥ä»£å…¥
        
        // ã‚µã‚¤ã‚ºãŒæœŸå¾…é€šã‚Šã‹ãƒã‚§ãƒƒã‚¯
        guard height == 256, width == 256 else {
            addDebugMessage("Error [convertMultiArray]: MLMultiArray height or width is incorrect: \(multiArray.shape). Expected [1, 3, 256, 256]")
            return nil
        }
        // --- ä¿®æ­£ã“ã“ã¾ã§ ---
        
        
        let count = width * height
        let channelStride = count // For CHW layout
        
        let rawPointer = multiArray.dataPointer
        let bufferPointer = UnsafeMutableBufferPointer<Float32>(start: rawPointer.assumingMemoryBound(to: Float32.self),
                                                                count: 3 * count) // Total number of floats
        
        var pixelData = [UInt8](repeating: 0, count: count * 4) // RGBA buffer
        
        // ... (ä»¥é™ã®ãƒ”ã‚¯ã‚»ãƒ«å‡¦ç†ã€CGImageä½œæˆã¯å¤‰æ›´ãªã—) ...
        for i in 0..<count {
            guard i < bufferPointer.count,
                  channelStride + i < bufferPointer.count,
                  channelStride * 2 + i < bufferPointer.count else {
                addDebugMessage("Error [convertMultiArray]: Index out of bounds while accessing buffer pointer at index \(i).")
                return nil
            }
            
            let rTanh = bufferPointer[i]
            let gTanh = bufferPointer[channelStride + i]
            let bTanh = bufferPointer[channelStride * 2 + i]
            
            let r_01 = (rTanh + 1.0) / 2.0
            let g_01 = (gTanh + 1.0) / 2.0
            let b_01 = (bTanh + 1.0) / 2.0
            
            let r = UInt8(clamping: Int(round(r_01 * 255.0)))
            let g = UInt8(clamping: Int(round(g_01 * 255.0)))
            let b = UInt8(clamping: Int(round(b_01 * 255.0)))
            
            let offset = i * 4
            pixelData[offset]     = r
            pixelData[offset + 1] = g
            pixelData[offset + 2] = b
            pixelData[offset + 3] = 255
        }
        
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        let bitmapInfo = CGBitmapInfo(rawValue: CGImageAlphaInfo.premultipliedLast.rawValue)
        let bitsPerComponent = 8
        let bitsPerPixel = 32
        let bytesPerRow = width * 4
        
        guard let providerRef = CGDataProvider(data: Data(bytes: pixelData, count: count * 4) as CFData) else {
            addDebugMessage("Error [convertMultiArray]: Failed to create CGDataProvider.")
            return nil
        }
        
        guard let cgImage = CGImage(
            width: width, height: height, bitsPerComponent: bitsPerComponent, bitsPerPixel: bitsPerPixel, bytesPerRow: bytesPerRow,
            space: colorSpace, bitmapInfo: bitmapInfo, provider: providerRef, decode: nil, shouldInterpolate: true, intent: .defaultIntent
        ) else {
            addDebugMessage("Error [convertMultiArray]: Failed to create CGImage.")
            return nil
        }
        addDebugMessage("âœ… UIImage conversion successful.")
        return UIImage(cgImage: cgImage)
    }
}

// --- è¿½åŠ : ã‚¨ãƒ©ãƒ¼å‹å®šç¾© ---
enum ConversionError: Error, LocalizedError {
    case preprocessingFailed(String)
    case bufferCreationFailed(String)
    case referenceImageLoadFailed(String)
    case multiArrayCreationFailed(String)
    case postprocessingFailed(String)
    
    var errorDescription: String? {
        switch self {
        case .preprocessingFailed(let reason): return "Preprocessing failed: \(reason)"
        case .bufferCreationFailed(let reason): return "CVPixelBuffer creation failed: \(reason)"
        case .referenceImageLoadFailed(let reason): return "Reference image load failed: \(reason)"
        case .multiArrayCreationFailed(let reason): return "MLMultiArray creation failed: \(reason)"
        case .postprocessingFailed(let reason): return "Postprocessing failed: \(reason)"
        }
    }
}
